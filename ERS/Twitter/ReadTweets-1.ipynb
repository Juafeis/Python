{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "states = [\"ak\",\"al\",\"ar\",\"az\",\"ca\",\"co\",\"ct\",\"de\",\"fl\",\"ga\",\"hi\",\"ia\",\"id\",\"il\",\n",
    "          \"in\",\"ks\",\"ky\",\"la\",\"ma\",\"md\",\"me\",\"mi\",\"mn\",\"mo\",\"ms\",\"mt\",\"nc\",\"nd\",\"ne\",\"nh\",\n",
    "          \"nj\",\"nm\",\"nv\",\"ny\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"va\",\"vt\",\n",
    "          \"wa\",\"wi\",\"wv\",\"wy\"]\n",
    "states_names = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois',\n",
    "'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC':'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island',\n",
    "'SC': 'South Carolina', 'SD': 'South Dakota', 'TN':'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "'WA': 'Washington','WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer los tweets del fichero output.txt y guardarlos en la variable tweets\n",
    "with open('output.txt') as json_file:\n",
    "    tweets = json.load(json_file)\n",
    "\n",
    "    \n",
    "def getState(data):\n",
    "    if data[\"place\"] != None and data[\"place\"][\"country_code\"] == \"US\":\n",
    "        state = str(data[\"place\"][\"full_name\"]).lower().split(\", \")\n",
    "        if len(state) > 1:\n",
    "            return state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the tweet data, check for states and non-empty tweets, \n",
    "#add those to sent_dict, where a key is a state and the value\n",
    "#now we analyze those tweets\n",
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "sent_dict = {}\n",
    "\n",
    "score_dict = dict.fromkeys(sent_dict.keys())\n",
    "for entry in sent_dict:\n",
    "    #scoring each set of tweets from each state\n",
    "    total = 0\n",
    "    for tweet in sent_dict[entry]:\n",
    "        #calculating the normalized happiness for the tweets\n",
    "        score = afinn.score(tweet)/len(sent_dict[entry])\n",
    "        total = total + score\n",
    "    score_dict[entry] = total\n",
    "#add the states without tweets with a happiness value of 0\n",
    "for state in states:\n",
    "    if state not in score_dict.keys():\n",
    "        score_dict[state] = 0\n",
    "#and returning the 5 happiest states as well as the score_dict\n",
    "result = sorted(score_dict, key=score_dict.get, reverse=True)[:5],score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happiest five states are ['ky', 'sc', 'vt', 'mo', 'wa']\n"
     ]
    }
   ],
   "source": [
    "#saving the results and sorting them\n",
    "\n",
    "for entry in tweets:\n",
    "        if \"created_at\" in entry:\n",
    "            state = getState(entry)\n",
    "            if state in states:\n",
    "                if \"text\" in entry:\n",
    "                    if state not in sent_dict.keys():\n",
    "                        sent_dict[state] = [entry[\"text\"]]\n",
    "                    else:\n",
    "                        sent_dict[state].append(entry[\"text\"])\n",
    "\n",
    "result = evaluateDict()\n",
    "print(\"happiest five states are \"+str(result[0]))\n",
    "\n",
    "#sorting the keys descending and readding the values so that\n",
    "#the map can be populated properly\n",
    "score_dict = result[1]\n",
    "buffer = {}\n",
    "for key in sorted(score_dict):\n",
    "    buffer[key]=score_dict[key]\n",
    "score_dict = buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#painting the USA graph\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "global score_dict\n",
    "\n",
    "# Load data frame and tidy it.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv')\n",
    "\n",
    "#generating the plit\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=df['code'], # Spatial coordinates\n",
    "    z = list(score_dict.values()),# our sentiment data\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Portland',\n",
    "    colorbar_title = 'Grado de felicidad',\n",
    "))\n",
    "\n",
    "#adding layout\n",
    "fig.update_layout(\n",
    "    title_text = 'Estados m√°s felices de EEUU',\n",
    "    geo_scope='usa', # limite map scope to USA\n",
    ")\n",
    "\n",
    "fig.write_html(\"file.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
